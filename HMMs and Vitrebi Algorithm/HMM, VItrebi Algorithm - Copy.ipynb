{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models, Vitrebi Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the Viterbi algorithm to solve the problem of unknown words using at least two techniques. \n",
    "\n",
    "\n",
    "1. Which tag class do you think most unknown words belong to? Can you identify rules (e.g. based on morphological cues) that can be used to tag unknown words? You may define separate python functions to exploit these rules so that they work in tandem with the original Viterbi algorithm.\n",
    "2. Why does the Viterbi algorithm choose a random tag on encountering an unknown word? Can you modify the Viterbi algorithm so that it considers only one of the transition or emission probabilities for unknown words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing NLTK libraries and resources\n",
    "import nltk\n",
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged with universal tagset\n",
    "universalTreebankDataset = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the tags and first few sentences\n",
    "pp.pprint(universalTreebankDataset[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test-train split: 95-5\n",
    "train_set, validation_set = train_test_split(universalTreebankDataset,test_size=0.05,random_state=1331,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_set))\n",
    "print(len(validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(train_set[:20])\n",
    "pp.pprint(validation_set[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtaining the nuber of tuples which are tagged in train set:\n",
    "taggedWordsInTrainDataset=[t for s in train_set for t in s ]\n",
    "print(len(taggedWordsInTrainDataset))\n",
    "print(taggedWordsInTrainDataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#finding teh tagged words i.e. knows words:\n",
    "knownWords=[taggedWordSet[0] for taggedWordSet in taggedWordsInTrainDataset ]\n",
    "print(len(set(knownWords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the number of tokens:\n",
    "tagsUsed=[taggedWordSet[1] for taggedWordSet in taggedWordsInTrainDataset ]\n",
    "print(len(set(tagsUsed)))\n",
    "print(set(tagsUsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the test data provided:\n",
    "file=open('Sample_Test_Sentences.txt','r')\n",
    "testData=file.readlines();\n",
    "file.close();\n",
    "print(testData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla HMM with Vitrebi Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. HMM- Hidden Markov Models use stocastic methods to model sequential processes.\n",
    "2. Using the first order markovian assumption, the probability of a state depends only on the probability of the previous state.\n",
    "3. HMM have hidden states, which emit the probabilty of observations. \n",
    "4. These probabilties are called the Emission probabilites.\n",
    "5. The probability of one state coming after another is called transition probabitliy, as there is a tarnsition from one state to another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using HMM, we will assign a tag (say t) to a word (say w), such that the liklihood P(t|w) is maximum.\n",
    "Now, \n",
    "$P(t|w) = {P(w|t)*P(t)}/P(w)$\n",
    "is the formula for the liklihood.\n",
    "\n",
    "To compute it we can use the count of the tags and words computed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emission Probabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmissionProbability_WordgivenTag(word, tag, train_data = taggedWordsInTrainDataset):\n",
    "    tag_list = [pair for pair in train_data if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransitionProbability_t2_given_t1(t2, t1, train_bag = taggedWordsInTrainDataset):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a transion matrix that will give the probability of state transiton from one tag(ti) to another(tj)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagTransiontMatrix = np.zeros((len(set(tagsUsed)), len(set(tagsUsed))), dtype='float32')\n",
    "for i, t1 in enumerate(list(set(tagsUsed))):\n",
    "    for j, t2 in enumerate(list(set(tagsUsed))): \n",
    "        tagTransiontMatrix[i, j] = TransitionProbability_t2_given_t1(t2, t1)[0]/TransitionProbability_t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagTransiontMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagTransionDF=pd.DataFrame(tagTransiontMatrix, columns = list(set(tagsUsed)), index=list(set(tagsUsed)))\n",
    "display(tagTransionDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(tagTransionDF)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vitrebi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "class Viterbi:\n",
    "    this.taggedWordsInTrainDataset=\"\"\n",
    "    \n",
    "    def tag(words, train_bag = taggedWordsInTrainDataset):\n",
    "        state = []\n",
    "        T = list(set([pair[1] for pair in train_bag]))\n",
    "\n",
    "        for key, word in enumerate(words):\n",
    "            #initialise list of probability column for a given observation\n",
    "            p = [] \n",
    "            for tag in T:\n",
    "                if key == 0:\n",
    "                    transition_p = tagTransionDF.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = tagTransionDF.loc[state[-1], tag]\n",
    "\n",
    "                # compute emission and state probabilities\n",
    "                emission_p = EmissionProbability_WordgivenTag(words[key], tag)[0]/EmissionProbability_WordgivenTag(words[key], tag)[1]\n",
    "                state_probability = emission_p * transition_p    \n",
    "                p.append(state_probability)\n",
    "\n",
    "            pmax = max(p)\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)] \n",
    "            state.append(state_max)\n",
    "        return list(zip(words, state))\n",
    "    def EmissionProbability_WordgivenTag(word, tag, train_data = taggedWordsInTrainDataset):\n",
    "        tag_list = [pair for pair in train_data if pair[1]==tag]\n",
    "        count_tag = len(tag_list)\n",
    "        w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "        count_w_given_tag = len(w_given_tag_list)\n",
    "\n",
    "        return (count_w_given_tag, count_tag)\n",
    "    def TransitionProbability_t2_given_t1(t2, t1, train_bag = taggedWordsInTrainDataset):\n",
    "        tags = [pair[1] for pair in train_bag]\n",
    "        count_t1 = len([t for t in tags if t==t1])\n",
    "        count_t2_t1 = 0\n",
    "        for index in range(len(tags)-1):\n",
    "            if tags[index]==t1 and tags[index+1] == t2:\n",
    "                count_t2_t1 += 1\n",
    "        return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of sents\n",
    "test_run = validation_set\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "print(test_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_run_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy\n",
    "def FindAccuracy(tagged_seq,test_run_base):\n",
    "    check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "    accuracy = len(check)/len(tagged_seq)\n",
    "    print(\"Validation Accuracy= \"+str(accuracy));\n",
    "    print(\"time taken= \"+str(difference))\n",
    "    \n",
    "FindAccuracy(tagged_seq,test_run_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrect tagged cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for testSentence in testData:\n",
    "    words = word_tokenize(testSentence)\n",
    "    tagged_seq = Viterbi(words)\n",
    "    difference = end-start\n",
    "    print(tagged_seq)\n",
    "    print(pos_tag(word_tokenize(testSentence),tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FindAccuracy(tagged_seq,test_run_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk import pos_tag\n",
    "for\n",
    "pos_tag(word_tokenize(testData[1]),tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifications to Address the issues with unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARISION: Tagging Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VANILLA TAGGER VS MODIFIED TAGGER: TEST CASES  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
